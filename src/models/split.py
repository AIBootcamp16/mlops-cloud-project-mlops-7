import os
import sys
sys.path.append('/app')

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from src.data.s3_pull_processed import get_processed_data
from src.utils.utils import set_seed

def split_and_scale_data(test_size=0.2, val_size=0.2, random_state=42):
    """
    S3ì—ì„œ ë°ì´í„° ë¡œë“œ í›„ train/val/test ë¶„í•  ë° ìŠ¤ì¼€ì¼ë§
    
    Args:
        test_size: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨
        val_size: ê²€ì¦ ë°ì´í„° ë¹„ìœ¨ 
        random_state: ëœë¤ ì‹œë“œ
        
    Returns:
        tuple: (X_train, X_val, X_test, y_train, y_val, y_test, scaler)
    """
    print("ğŸ”„ S3ì—ì„œ ë°ì´í„° ë¡œë“œ ì¤‘...")
    
    # ì‹œë“œ ê³ ì •
    set_seed(random_state)
    
    # S3ì—ì„œ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ëœ ë°ì´í„° ë¡œë“œ
    df = get_processed_data()
    print(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {df.shape}")
    
    # íƒ€ê²Ÿ ë³€ìˆ˜ ì„¤ì • (ì¾Œì ì§€ìˆ˜ ì˜ˆì¸¡)
    target_col = "comfort_score"
    exclude_cols = [target_col, "pm10", "datetime", "station_id"]  # pm10ë„ ì œì™¸
    feature_cols = [col for col in df.columns if col not in exclude_cols]
    
    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (-99, -9ë¥¼ NaNìœ¼ë¡œ ë³€í™˜)
    X = df[feature_cols].copy()
    X = X.replace([-99, -9], np.nan)
    
    # ê²°ì¸¡ì¹˜ ë¹„ìœ¨ì´ ë†’ì€ ì»¬ëŸ¼ ì œê±° (50% ì´ìƒ)
    high_missing_cols = []
    for col in X.columns:
        missing_ratio = X[col].isnull().sum() / len(X)
        if missing_ratio > 0.5:  # 50% ì´ìƒ ê²°ì¸¡ì¹˜ë©´ ì œê±°
            high_missing_cols.append(col)
    
    if high_missing_cols:
        print(f"ê²°ì¸¡ì¹˜ ë§ì€ ì»¬ëŸ¼ ì œê±°: {high_missing_cols}")
        X = X.drop(columns=high_missing_cols)
        feature_cols = [col for col in feature_cols if col not in high_missing_cols]
    
    # ë‚˜ë¨¸ì§€ ê²°ì¸¡ì¹˜ëŠ” í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´ (ìˆ˜ì¹˜í˜•ë§Œ)
    numeric_cols = X.select_dtypes(include=[np.number]).columns
    X[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())
    
    # ë²”ì£¼í˜• ë³€ìˆ˜ ì›í•«ì¸ì½”ë”©
    categorical_cols = ['season', 'temp_category', 'pm10_grade', 'region']
    categorical_cols = [col for col in categorical_cols if col in X.columns]
    
    if categorical_cols:
        print(f"ì›í•«ì¸ì½”ë”© ì ìš©: {categorical_cols}")
        X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)
    
    y = df[target_col].fillna(df[target_col].mean())
    
    print(f"í”¼ì²˜: {len(feature_cols)}ê°œ, ìƒ˜í”Œ: {len(X)}ê°œ")
    
    # Train/Test ë¶„í• 
    X_temp, X_test, y_temp, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state
    )
    
    # Train/Val ë¶„í• 
    val_ratio = val_size / (1 - test_size)
    X_train, X_val, y_train, y_val = train_test_split(
        X_temp, y_temp, test_size=val_ratio, random_state=random_state
    )
    
    print(f"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}")
    
    # ìŠ¤ì¼€ì¼ë§
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)
    X_test_scaled = scaler.transform(X_test)
    
    print("âœ… ë°ì´í„° ë¶„í•  ë° ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ")
    
    # ì›í•«ì¸ì½”ë”© í›„ í”¼ì²˜ ì»¬ëŸ¼ ëª©ë¡ ì €ì¥
    feature_columns = list(X.columns)
    
    return X_train_scaled, X_val_scaled, X_test_scaled, y_train, y_val, y_test, scaler, feature_columns

if __name__ == "__main__":
    split_and_scale_data()




