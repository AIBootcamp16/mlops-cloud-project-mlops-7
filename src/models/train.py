import os
import sys
sys.path.append('/app')

import pandas as pd
import numpy as np
import pickle
import datetime
from sklearn.metrics import mean_squared_error, mean_absolute_error
import fire
import wandb

from src.models.split import split_and_scale_data
from src.utils.utils import set_seed, auto_increment_run_suffix, save_model_to_s3

from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor
from lightgbm import LGBMRegressor
from xgboost import XGBRegressor
from catboost import CatBoostRegressor


def get_runs(entity, project):
    """WANDB í”„ë¡œì íŠ¸ì˜ ëª¨ë“  ì‹¤í–‰ ì¡°íšŒ"""
    return wandb.Api().runs(path=f"{entity}/{project}", order="-created_at")


def get_latest_run_name(entity, project, prefix="weather-predictor"):
    """ìµœì‹  ì‹¤í—˜ëª… ì¡°íšŒ"""
    runs = get_runs(entity, project)
    matching_runs = [run.name for run in runs if run.name.startswith(prefix)]
    if not matching_runs:
        return f"{prefix}-000"  # ì²« ì‹¤í–‰ì„ ìœ„í•œ ê¸°ë³¸ê°’
    return matching_runs[0]  # ê°€ì¥ ìµœì‹ 

def _get_requirements():
    """requirements.txt íŒŒì¼ ì½ê¸°"""
    try:
        with open('/app/requirements.txt', 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        return "requirements.txt not found"

def get_model(name, params=None):
    """ëª¨ë¸ íŒ©í† ë¦¬ í•¨ìˆ˜"""
    if params is None:
        params = {}
    
    if name == 'linear':
        return LinearRegression(**params)
    elif name == 'ridge':
        return Ridge(random_state=42, **params)
    elif name == 'lasso':
        return Lasso(random_state=42, **params)
    elif name == 'rf':
        return RandomForestRegressor(random_state=42, **params)
    elif name == 'lgbm':
        return LGBMRegressor(random_state=42, verbose=-1, **params)
    elif name == 'xgb':
        return XGBRegressor(random_state=42, **params)
    elif name == 'cat':
        return CatBoostRegressor(random_state=42, verbose=False, **params)
    else:
        raise ValueError(f"Unknown model: {name}")

def train_models(
    model_names=['linear', 'ridge', 'lasso', 'rf', 'lgbm', 'xgb', 'cat'],
    test_size=0.2,
    val_size=0.2,
    random_state=42,
    wandb_project=None
):
    """
    ì—¬ëŸ¬ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ í›„ ë² ìŠ¤íŠ¸ ëª¨ë¸ S3 ì €ì¥
    
    Args:
        model_names: í•™ìŠµí•  ëª¨ë¸ ë¦¬ìŠ¤íŠ¸
        test_size: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨
        val_size: ê²€ì¦ ë°ì´í„° ë¹„ìœ¨
        random_state: ëœë¤ ì‹œë“œ
        wandb_project: wandb í”„ë¡œì íŠ¸ëª…
    """
    # ì‹œë“œ ê³ ì •
    set_seed(random_state)
    
    # wandb ì´ˆê¸°í™” (ìµœì‹  ì‹¤í—˜ëª… ê¸°ë°˜)
    entity = os.getenv('WANDB_ENTITY')
    wandb_project = wandb_project or os.getenv('WANDB_PROJECT')
    latest_run_name = get_latest_run_name(entity, wandb_project)
    experiment_name = auto_increment_run_suffix(latest_run_name)
    wandb.init(project=wandb_project, name=experiment_name)
    
    print("ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    
    # 1. ë°ì´í„° ë¡œë“œ (split.py í™œìš©)
    X_train, X_val, X_test, y_train, y_val, y_test, scaler = split_and_scale_data(
        test_size=test_size, val_size=val_size, random_state=random_state
    )
    
    # 2. ëª¨ë¸ë³„ í•™ìŠµ ë° í‰ê°€ (models_plan.md ì°¸ì¡°)
    results = {}
    models = {}
    
    for model_name in model_names:
        print(f"\nğŸ“Š {model_name.upper()} ëª¨ë¸ í•™ìŠµ ì¤‘...")
        
        # ëª¨ë¸ ìƒì„±
        model = get_model(model_name)
        
        # í•™ìŠµ
        model.fit(X_train, y_train)
        
        # ì˜ˆì¸¡
        train_pred = model.predict(X_train)
        val_pred = model.predict(X_val)
        test_pred = model.predict(X_test)
        
        # í‰ê°€ ì§€í‘œ ê³„ì‚°
        train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))
        val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))
        test_rmse = np.sqrt(mean_squared_error(y_test, test_pred))
        
        train_mae = mean_absolute_error(y_train, train_pred)
        val_mae = mean_absolute_error(y_val, val_pred)
        test_mae = mean_absolute_error(y_test, test_pred)
        
        # ê²°ê³¼ ì €ì¥
        result = {
            'train_rmse': train_rmse,
            'val_rmse': val_rmse,
            'test_rmse': test_rmse,
            'train_mae': train_mae,
            'val_mae': val_mae,
            'test_mae': test_mae
        }
        results[model_name] = result
        models[model_name] = model
        
        # wandb ë¡œê¹…
        wandb.log({
            f"{model_name}_train_rmse": train_rmse,
            f"{model_name}_val_rmse": val_rmse,
            f"{model_name}_test_rmse": test_rmse,
            f"{model_name}_train_mae": train_mae,
            f"{model_name}_val_mae": val_mae,
            f"{model_name}_test_mae": test_mae
        })
        
        print(f"âœ… {model_name}: Val RMSE={val_rmse:.4f}, Test RMSE={test_rmse:.4f}")
    
    # 3. ë² ìŠ¤íŠ¸ ëª¨ë¸ ì„ íƒ (Validation RMSE ê¸°ì¤€)
    best_model_name = min(results.keys(), key=lambda x: results[x]['val_rmse'])
    best_model = models[best_model_name]
    best_result = results[best_model_name]
    
    print(f"\nğŸ† ë² ìŠ¤íŠ¸ ëª¨ë¸: {best_model_name.upper()}")
    print(f"   Val RMSE: {best_result['val_rmse']:.4f}")
    print(f"   Test RMSE: {best_result['test_rmse']:.4f}")
    
    # wandbì— ë² ìŠ¤íŠ¸ ëª¨ë¸ ë¡œê¹…
    wandb.log({
        "best_model": best_model_name,
        "best_val_rmse": best_result['val_rmse'],
        "best_test_rmse": best_result['test_rmse']
    })
    
    # 4. ë² ìŠ¤íŠ¸ ëª¨ë¸ ì²´ê³„ì  êµ¬ì¡°ë¡œ S3 ì €ì¥
    current_time = datetime.datetime.now().strftime("%y%m%d_%H%M%S")
    
    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶”ì¶œ (ëª¨ë¸ë³„ë¡œ)
    hyperparameters = {}
    if hasattr(best_model, 'get_params'):
        hyperparameters = best_model.get_params()
    
    # S3 ì €ì¥ìš© ëª¨ë¸ ë°ì´í„° íŒ¨í‚¤ì§•
    model_data = {
        "model": best_model,                    # í•™ìŠµëœ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ê°ì²´ â†’ model_artifact/model.pkl
        "scaler": scaler,                       # ì „ì²˜ë¦¬ìš© StandardScaler ê°ì²´ â†’ model_artifact/scaler.pkl
        "model_name": best_model_name,          # ëª¨ë¸ëª… (ì˜ˆ: 'rf') â†’ metadata/experiment_log.json
        "metrics": best_result,                 # ì„±ëŠ¥ ì§€í‘œ (RMSE, MAE) â†’ metadata/metrics.json
        "experiment_name": experiment_name,     # ì‹¤í—˜ëª… (ì˜ˆ: 'weather-predictor-006') â†’ metadata/experiment_log.json
        "wandb_project": wandb_project,         # WANDB í”„ë¡œì íŠ¸ëª… â†’ metadata/experiment_log.json
        "timestamp": current_time,              # í•™ìŠµ ì™„ë£Œ ì‹œê°„ â†’ metadata/experiment_log.json
        "hyperparameters": hyperparameters,     # ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° â†’ config/train_config.json
        "data_info": {                          # ë°ì´í„° ì •ë³´ â†’ config/data_info.json
            "target": "comfort_score",          # íƒ€ê²Ÿ ë³€ìˆ˜ëª…
            "model_type": "regression",         # ëª¨ë¸ ìœ í˜• (íšŒê·€)
            "train_samples": len(y_train),      # í•™ìŠµ ë°ì´í„° ìƒ˜í”Œ ìˆ˜
            "val_samples": len(y_val),          # ê²€ì¦ ë°ì´í„° ìƒ˜í”Œ ìˆ˜
            "test_samples": len(y_test),        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒ˜í”Œ ìˆ˜
            "features": X_train.shape[1]        # í”¼ì²˜ ê°œìˆ˜ (ì›í•«ì¸ì½”ë”© í›„)
        },
        "requirements": _get_requirements()     # íŒ¨í‚¤ì§€ ë²„ì „ ì •ë³´ â†’ config/requirements.txt
    }
    
    base_path = f"models/{experiment_name}"
    save_model_to_s3(model_data, os.getenv('S3_BUCKET'), base_path)
    
    wandb.finish()
    print("ğŸ‰ í•™ìŠµ ì™„ë£Œ!")
    
    return best_model, best_result

if __name__ == "__main__":
    fire.Fire(train_models)
