import os
import sys
sys.path.append('/app')

import pandas as pd
import numpy as np
import pickle
import datetime
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error
import fire
import wandb

from src.models.split import split_and_scale_data
from src.utils.utils import set_seed, save_model_to_s3
from src.utils.model_utils import get_model
from src.utils.wandb_utils import get_latest_run_name, get_requirements



def tune_rf_hyperparameters(
    search_type="grid",  # "grid" or "random"
    cv_folds=3,
    n_iter=20,  # RandomizedSearchCVìš©
    test_size=0.2,
    val_size=0.2,
    random_state=42,
    wandb_project=None
):
    """
    Random Forest í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
    
    Args:
        search_type: "grid" ë˜ëŠ” "random"
        cv_folds: Cross-validation folds ìˆ˜
        n_iter: RandomizedSearchCV ë°˜ë³µ íšŸìˆ˜
        test_size: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨
        val_size: ê²€ì¦ ë°ì´í„° ë¹„ìœ¨  
        random_state: ëœë¤ ì‹œë“œ
        wandb_project: wandb í”„ë¡œì íŠ¸ëª…
    """
    # ì‹œë“œ ê³ ì •
    set_seed(random_state)
    
    # wandb ì´ˆê¸°í™”
    entity = os.getenv('WANDB_ENTITY') or 'realtheai-insight-'
    wandb_project = wandb_project or os.getenv('WANDB_PROJECT') or 'weather-predictor'
    
    # ì‹¤í—˜ëª… ìƒì„± (tune ì ‘ë‘ì‚¬ ì‚¬ìš©)
    latest_run_name = get_latest_run_name(entity, wandb_project, prefix="rf-tune")
    if latest_run_name == "rf-tune-000":
        experiment_name = "rf-tune-001"
    else:
        num = int(latest_run_name.split("-")[-1]) + 1
        experiment_name = f"rf-tune-{str(num).zfill(3)}"
    
    wandb.init(entity=entity, project=wandb_project, name=experiment_name)
    
    print(f"ğŸš€ RF í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘... ({search_type.upper()})")
    
    # 1. ë°ì´í„° ë¡œë“œ
    X_train, X_val, X_test, y_train, y_val, y_test, scaler = split_and_scale_data(
        test_size=test_size, val_size=val_size, random_state=random_state
    )
    
    # í•™ìŠµìš© ë°ì´í„° ê²°í•© (train + val)
    X_train_full = np.vstack([X_train, X_val])
    y_train_full = np.hstack([y_train, y_val])
    
    print(f"íŠœë‹ìš© ë°ì´í„°: {X_train_full.shape}, í…ŒìŠ¤íŠ¸: {X_test.shape}")
    
    # 2. í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜
    param_grid = {
        'n_estimators': [100, 200, 300],
        'max_depth': [10, 15, 20, None],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4],
        'max_features': ['sqrt', 'log2', None]
    }
    
    # RandomizedSearchìš© ë” ë„“ì€ ë²”ìœ„
    param_random = {
        'n_estimators': [50, 100, 150, 200, 300, 400],
        'max_depth': [5, 10, 15, 20, 25, None],
        'min_samples_split': [2, 5, 10, 15, 20],
        'min_samples_leaf': [1, 2, 4, 6, 8],
        'max_features': ['sqrt', 'log2', None, 0.3, 0.5, 0.7]
    }
    
    # 3. ëª¨ë¸ ë° ì„œì¹˜ ê°ì²´ ìƒì„±
    rf = RandomForestRegressor(random_state=random_state, n_jobs=-1)
    
    if search_type == "grid":
        search = GridSearchCV(
            rf, param_grid, 
            cv=cv_folds, 
            scoring='neg_mean_squared_error',
            n_jobs=-1, 
            verbose=1
        )
        params_used = param_grid
    else:  # random
        search = RandomizedSearchCV(
            rf, param_random,
            n_iter=n_iter,
            cv=cv_folds,
            scoring='neg_mean_squared_error',
            n_jobs=-1,
            verbose=1,
            random_state=random_state
        )
        params_used = param_random
    
    # 4. í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„œì¹˜ ì‹¤í–‰
    print(f"ğŸ“Š {search_type.upper()} ì„œì¹˜ ì‹¤í–‰ ì¤‘...")
    search.fit(X_train_full, y_train_full)
    
    # 5. ìµœì  ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ í‰ê°€
    best_model = search.best_estimator_
    
    # ì˜ˆì¸¡
    train_pred = best_model.predict(X_train_full)
    test_pred = best_model.predict(X_test)
    
    # í‰ê°€ ì§€í‘œ ê³„ì‚°
    train_rmse = np.sqrt(mean_squared_error(y_train_full, train_pred))
    test_rmse = np.sqrt(mean_squared_error(y_test, test_pred))
    train_mae = mean_absolute_error(y_train_full, train_pred)
    test_mae = mean_absolute_error(y_test, test_pred)
    
    # CV ì ìˆ˜
    cv_rmse = np.sqrt(-search.best_score_)
    
    print(f"\nğŸ† ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:")
    for param, value in search.best_params_.items():
        print(f"   {param}: {value}")
    
    print(f"\nğŸ“Š ì„±ëŠ¥ ê²°ê³¼:")
    print(f"   CV RMSE: {cv_rmse:.4f}")
    print(f"   Train RMSE: {train_rmse:.4f}")
    print(f"   Test RMSE: {test_rmse:.4f}")
    
    # 6. WANDB ë¡œê¹…
    wandb.log({
        "search_type": search_type,
        "cv_folds": cv_folds,
        "cv_rmse": cv_rmse,
        "train_rmse": train_rmse,
        "test_rmse": test_rmse,
        "train_mae": train_mae,
        "test_mae": test_mae,
        **{f"best_{k}": v for k, v in search.best_params_.items()}
    })
    
    # ìƒìœ„ 5ê°œ ê²°ê³¼ë„ ë¡œê¹…
    results_df = pd.DataFrame(search.cv_results_)
    top_5 = results_df.nlargest(5, 'mean_test_score')
    
    for i, (idx, row) in enumerate(top_5.iterrows()):
        wandb.log({f"top_{i+1}_cv_rmse": np.sqrt(-row['mean_test_score'])})
    
    # 7. ìµœì  ëª¨ë¸ S3 ì €ì¥
    current_time = datetime.datetime.now().strftime("%y%m%d_%H%M%S")
    
    model_data = {
        "model": best_model,
        "scaler": scaler,
        "model_name": "rf_tuned",
        "metrics": {
            "cv_rmse": cv_rmse,
            "train_rmse": train_rmse,
            "test_rmse": test_rmse,
            "train_mae": train_mae,
            "test_mae": test_mae
        },
        "experiment_name": experiment_name,
        "wandb_project": wandb_project,
        "timestamp": current_time,
        "hyperparameters": search.best_params_,
        "tuning_info": {
            "search_type": search_type,
            "cv_folds": cv_folds,
            "param_space": params_used,
            "n_iter": n_iter if search_type == "random" else "all_combinations"
        },
        "data_info": {
            "target": "comfort_score",
            "model_type": "regression_tuned",
            "train_samples": len(y_train_full),
            "test_samples": len(y_test),
            "features": X_train_full.shape[1]
        },
        "requirements": get_requirements()
    }
    
    base_path = f"models/{experiment_name}"
    save_model_to_s3(model_data, os.getenv('S3_BUCKET'), base_path)
    
    wandb.finish()
    print("ğŸ‰ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì™„ë£Œ!")
    
    return best_model, search.best_params_, cv_rmse


if __name__ == "__main__":
    fire.Fire(tune_rf_hyperparameters) 