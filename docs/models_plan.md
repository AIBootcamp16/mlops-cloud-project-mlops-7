
ë§ìŠµë‹ˆë‹¤! 

`split.py`ì—ì„œëŠ” S3 ì €ì¥ ì•ˆ í•´ë„ ë©ë‹ˆë‹¤.

1. **S3ì—ì„œ ë°ì´í„° ë¡œë“œ**
2. **train/validation/test ë¶„ë¦¬**
3. **ì •ê·œí™”/í‘œì¤€í™”**
4. **ë©”ëª¨ë¦¬ì—ì„œ ë°”ë¡œ return** (train_X, train_y, val_X, val_y, test_X, test_y)

ê·¸ëŸ¬ë©´ `train.py`ì—ì„œ `split.py`ì˜ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•´ì„œ ë°”ë¡œ ë°›ì•„ì„œ í•™ìŠµí•˜ë©´ ë˜ë‹ˆê¹Œ, êµ³ì´ ì¤‘ê°„ ê²°ê³¼ë¬¼ì„ S3ì— ë‹¤ì‹œ ì €ì¥í•  í•„ìš” ì—†ì£ .

ì„ì‹œ ë°ì´í„°ë¥¼ S3ì— ì €ì¥í•˜ëŠ” ê±´ ë¹„ìš©ë„ ë“¤ê³  ë¶ˆí•„ìš”í•œ I/Oì…ë‹ˆë‹¤.


ë„¤, ë§ìŠµë‹ˆë‹¤!

`train.py`ì—ì„œëŠ”:

1. **`split.py`ì—ì„œ ì¤€ë¹„ëœ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°** (í•¨ìˆ˜ í˜¸ì¶œ)
2. **ëª¨ë¸ í•™ìŠµ** (LightGBM, XGBoost ë“±)
3. **í•™ìŠµëœ ëª¨ë¸ì„ ë¡œì»¬ ë˜ëŠ” S3ì— ì €ì¥** (`.pkl`, `.joblib` ë“±)
4. **í•™ìŠµ ë©”íŠ¸ë¦­ ë¡œê¹…** (wandb, ë¡œê·¸ íŒŒì¼ ë“±)

ë°ì´í„° ì „ì²˜ë¦¬ë‚˜ ë¶„í• ì€ `split.py`ì—ì„œ ì´ë¯¸ ë‹¤ ì²˜ë¦¬í–ˆìœ¼ë‹ˆê¹Œ, `train.py`ëŠ” ìˆœìˆ˜í•˜ê²Œ **ëª¨ë¸ í•™ìŠµê³¼ ì €ì¥**ì—ë§Œ ì§‘ì¤‘í•˜ë©´ ë©ë‹ˆë‹¤.

ê¹”ë”í•œ ì—­í•  ë¶„ë¦¬ë„¤ìš”!


ë„¤, ë§ìŠµë‹ˆë‹¤!
train.pyì—ì„œ:
ì—¬ëŸ¬ ëª¨ë¸ í•™ìŠµ (RandomForest, LightGBM, XGBoost, CatBoost ë“±)
ê° ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ (RMSE, MAE ë“±ìœ¼ë¡œ ë¹„êµ)
ë² ìŠ¤íŠ¸ ëª¨ë¸ ì„ íƒ (ì„±ëŠ¥ ì§€í‘œ ê¸°ì¤€)
ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë§Œ S3ì— ì €ì¥ (best_model.pkl)
ì´ë ‡ê²Œ í•˜ë©´ ë‚˜ì¤‘ì— APIë‚˜ ë°°í¬ ë‹¨ê³„ì—ì„œ S3ì—ì„œ ë² ìŠ¤íŠ¸ ëª¨ë¸ë§Œ ë¡œë“œí•´ì„œ ì‚¬ìš©í•˜ë©´ ë˜ë‹ˆê¹Œ íš¨ìœ¨ì ì´ì£ .
ì‹¤í—˜ ê³¼ì •ì˜ ëª¨ë“  ëª¨ë¸ì„ ì €ì¥í•  í•„ìš” ì—†ì´, ìµœì¢… ì„ íƒëœ í•˜ë‚˜ë§Œ ì €ì¥í•˜ëŠ” ê²Œ ë§ìŠµë‹ˆë‹¤.

ë„¤, `train.py`ì— ë“¤ì–´ê°€ëŠ” ê²Œ ë§ìŠµë‹ˆë‹¤!

`train.py`ì—ì„œ:

1. **ì—¬ëŸ¬ ëª¨ë¸ í•™ìŠµ**
2. **ê° ëª¨ë¸ ì„±ëŠ¥ í‰ê°€** (validation setìœ¼ë¡œ)
3. **ë² ìŠ¤íŠ¸ ëª¨ë¸ ì„ íƒ**
4. **ìµœì¢… í…ŒìŠ¤íŠ¸ í‰ê°€** (test setìœ¼ë¡œ)
5. **ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥**

ëª¨ë¸ í•™ìŠµê³¼ í‰ê°€ëŠ” í•œ ì„¸íŠ¸ë‹ˆê¹Œ ë¶„ë¦¬í•  í•„ìš” ì—†ì–´ìš”. 

ë§Œì•½ ë‚˜ì¤‘ì— ë°°í¬ëœ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ëª¨ë‹ˆí„°ë§í•˜ê±°ë‚˜ ìƒˆë¡œìš´ ë°ì´í„°ë¡œ ì¬í‰ê°€í•˜ëŠ” ê±´ ë³„ë„ ìŠ¤í¬ë¦½íŠ¸(`evaluate.py` ê°™ì€)ë¡œ ë§Œë“¤ë©´ ë˜ì§€ë§Œ, í•™ìŠµ ê³¼ì •ì—ì„œì˜ í‰ê°€ëŠ” `train.py`ì— í¬í•¨ë˜ëŠ” ê²Œ ìì—°ìŠ¤ëŸ½ìŠµë‹ˆë‹¤.


----

ë„¤, ë§ìŠµë‹ˆë‹¤! wandb ì„¤ì •ê³¼ ë„¤ì´ë° ê·œì¹™ì€ ë³´í†µ ì´ë ‡ê²Œ ê´€ë¦¬í•´ìš”:
1. ì„¤ì • íŒŒì¼ë¡œ ê´€ë¦¬:
config/wandb_config.yaml ë˜ëŠ” config.pyì— í”„ë¡œì íŠ¸ëª…, ì‹¤í—˜ëª… ê·œì¹™ ì €ì¥
ë²„ì „ ê´€ë¦¬ (v01, v02...)ëŠ” ìë™ ì¦ê°€ ë˜ëŠ” ìˆ˜ë™ ì„¤ì •
2. í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬:
.env íŒŒì¼ì— WANDB_PROJECT, WANDB_ENTITY ë“± ì €ì¥
ë²„ì „ì€ ë‚ ì§œ ê¸°ë°˜ (20241201_v01) ë˜ëŠ” Git í•´ì‹œ í™œìš©
3. utils í•¨ìˆ˜ë¡œ ê´€ë¦¬:
src/utils/utils.pyì— get_experiment_name() ê°™ì€ í•¨ìˆ˜ ë§Œë“¤ì–´ì„œ
ìë™ìœ¼ë¡œ ë²„ì „ ë²ˆí˜¸ ì¦ê°€í•˜ëŠ” ë¡œì§ êµ¬í˜„
4. train.pyì—ì„œ ì§ì ‘ ê´€ë¦¬:
ì‹¤í—˜ ì‹œì‘í•  ë•Œ wandb.init()ì—ì„œ run_name ì„¤ì •
ë‚ ì§œ+ëª¨ë¸ëª…+ë²„ì „ ì¡°í•© (ì˜ˆ: "20241201_lightgbm_v01")
ë³´í†µ config íŒŒì¼ + utils í•¨ìˆ˜ ì¡°í•©ì„ ë§ì´ ì¨ìš”. ì´ë¯¸ src/utils/utils.pyì— auto_increment_run_suffix() í•¨ìˆ˜ê°€ ìˆìœ¼ë‹ˆê¹Œ ê·¸ê±¸ í™œìš©í•˜ë©´ ë  ê²ƒ ê°™ë„¤ìš”!

ì¢‹ì€ ì§€ì ì´ì—ìš”! ëª¨ë¸ ì„¤ì •ê°’ ì €ì¥ ë°©ë²•ì€ ì—¬ëŸ¬ ê°€ì§€ê°€ ìˆì–´ìš”:

**1. ëª¨ë¸ê³¼ í•¨ê»˜ ì €ì¥:**
- `joblib.dump({'model': best_model, 'params': best_params, 'scaler': scaler}, 'model_package.pkl')`
- ëª¨ë¸, í•˜ì´í¼íŒŒë¼ë¯¸í„°, ì „ì²˜ë¦¬ ê°ì²´ë¥¼ í•˜ë‚˜ì˜ íŒ¨í‚¤ì§€ë¡œ ì €ì¥

**2. ë³„ë„ ë©”íƒ€ë°ì´í„° íŒŒì¼:**
- `model_metadata.json` ë˜ëŠ” `model_config.yaml`ë¡œ S3ì— í•¨ê»˜ ì €ì¥
- ëª¨ë¸ íŒŒì¼ê³¼ ê°™ì€ ê²½ë¡œì— ì„¤ì •ê°’ë§Œ ë”°ë¡œ ì €ì¥

**3. MLflow ìŠ¤íƒ€ì¼:**
- `model/` í´ë” ì•ˆì— `model.pkl` + `MLmodel` + `conda.yaml` êµ¬ì¡°
- ëª¨ë¸, ì„¤ì •, ì˜ì¡´ì„±ì„ í´ë” ë‹¨ìœ„ë¡œ ê´€ë¦¬

**4. wandb artifact í™œìš©:**
- wandbì—ì„œ ëª¨ë¸ì„ artifactë¡œ ì €ì¥í•˜ë©´ ìë™ìœ¼ë¡œ ë©”íƒ€ë°ì´í„° í¬í•¨
- ë‚˜ì¤‘ì— wandbì—ì„œ ëª¨ë¸ + ì„¤ì • í•¨ê»˜ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥

ë³´í†µ **1ë²ˆ(íŒ¨í‚¤ì§€ë¡œ ì €ì¥)** ë˜ëŠ” **2ë²ˆ(ë©”íƒ€ë°ì´í„° ë¶„ë¦¬)**ë¥¼ ë§ì´ ì¨ìš”. ì´ë¯¸ wandb ì“°ì‹ ë‹¤ë©´ **4ë²ˆ**ì´ ê°€ì¥ ê¹”ë”í•  ê²ƒ ê°™ë„¤ìš”!


---
ì•„, ë©˜í† ë‹˜ì´ **ë©”íƒ€ë°ì´í„° ì¶”ì **ì„ ê°•ì¡°í•˜ì‹  ê±°ë„¤ìš”!

ê·¸ëŸ¬ë©´:

**1. wandbì—ì„œ ìë™ ë©”íƒ€ë°ì´í„° ì¶”ì :**
- `wandb.config.update(hyperparams)` ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œê¹…
- `wandb.log_model()` ë¡œ ëª¨ë¸ ì €ì¥í•˜ë©´ ìë™ìœ¼ë¡œ configë„ í•¨ê»˜ ì €ì¥ë¨

**2. ëª¨ë¸ ì €ì¥ ì‹œ ë©”íƒ€ë°ì´í„° í¬í•¨:**
```python
model_info = {
    'model': best_model,
    'hyperparameters': best_params,
    'metrics': best_scores,
    'training_date': datetime.now(),
    'data_version': 'v01',
    'scaler': scaler
}
```

**3. S3 ê°ì²´ ë©”íƒ€ë°ì´í„° í™œìš©:**
- S3ì— ì €ì¥í•  ë•Œ ê°ì²´ì˜ metadata í•„ë“œì— í•˜ì´í¼íŒŒë¼ë¯¸í„° ì •ë³´ ì¶”ê°€
- ë‚˜ì¤‘ì— ëª¨ë¸ ë¡œë“œí•  ë•Œ ë©”íƒ€ë°ì´í„°ë„ í•¨ê»˜ ì¡°íšŒ ê°€ëŠ¥

ë©˜í† ë‹˜ ì¡°ì–¸ì€ **ëª¨ë¸ê³¼ ì„¤ì •ì´ ë¶„ë¦¬ë˜ì§€ ì•Šê³  í•˜ë‚˜ì˜ ì •ë³´ ë‹¨ìœ„ë¡œ ì¶”ì ë˜ì–´ì•¼ í•œë‹¤**ëŠ” ëœ» ê°™ì•„ìš”. wandb artifactê°€ ì´ëŸ° ìš”êµ¬ì‚¬í•­ì— ê°€ì¥ ì í•©í•  ê²ƒ ê°™ë„¤ìš”!

----
`fire`ëŠ” Python í•¨ìˆ˜ë‚˜ í´ë˜ìŠ¤ë¥¼ **ì»¤ë§¨ë“œë¼ì¸ ì¸í„°í˜ì´ìŠ¤(CLI)**ë¡œ ìë™ ë³€í™˜í•´ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ˆìš”.

ì¦‰, `python split.py`, `python train.py` ê°™ì´ **ê° ìŠ¤í¬ë¦½íŠ¸ë¥¼ ê°œë³„ì ìœ¼ë¡œ ì‹¤í–‰**í•  ìˆ˜ ìˆê²Œ í•´ì£¼ê³ , í•¨ìˆ˜ì˜ íŒŒë¼ë¯¸í„°ë“¤ì„ **ì»¤ë§¨ë“œë¼ì¸ ì¸ì**ë¡œ ë°›ì„ ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.

ì˜ˆë¥¼ ë“¤ì–´:
- `python train.py --model_type=lightgbm --n_estimators=100`
- `python split.py --test_size=0.2 --random_state=42`

ì´ëŸ° ì‹ìœ¼ë¡œ **ê° ë‹¨ê³„ë¥¼ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰í•˜ë©´ì„œ íŒŒë¼ë¯¸í„°ë„ ìœ ì—°í•˜ê²Œ ì¡°ì •**í•  ìˆ˜ ìˆì–´ìš”. MLOps íŒŒì´í”„ë¼ì¸ì—ì„œ ê° ë‹¨ê³„ë¥¼ ë”°ë¡œë”°ë¡œ ëŒë¦¬ê±°ë‚˜ ë””ë²„ê¹…í•  ë•Œ ë§¤ìš° ìœ ìš©í•©ë‹ˆë‹¤.

---
**ì„¤ì¹˜:** `requirements.txt`ì— `fire==0.5.0` ì¶”ê°€í•˜ê³  `pip install fire`

**ì‚¬ìš©í•  íŒŒì¼ë“¤:**
- `split.py` - ë°ì´í„° ë¶„í•  í•¨ìˆ˜ë¥¼ CLIë¡œ
- `train.py` - ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜ë¥¼ CLIë¡œ  
- `data_cleaning.py` - ì „ì²˜ë¦¬ í•¨ìˆ˜ë¥¼ CLIë¡œ

**ì‚¬ìš© ë°©ë²•:**
ê° íŒŒì¼ ë§¨ ì•„ë˜ì— `fire.Fire()` ì¶”ê°€í•˜ë©´ ë!

```python
import fire

def my_function(param1, param2=default_value):
    # í•¨ìˆ˜ ë‚´ìš©
    pass

if __name__ == "__main__":
    fire.Fire()  # ì´ í•œ ì¤„ë§Œ ì¶”ê°€í•˜ë©´ CLI ì™„ì„±
```

ê·¸ëŸ¬ë©´ `python split.py --param1=value --param2=value` ì´ëŸ° ì‹ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•´ìš”.

**ì–¸ì œ ì„¤ì¹˜:** ì§€ê¸ˆ ë‹¹ì¥! ê° ëª¨ë“ˆì„ ê°œë³„ ì‹¤í–‰í•˜ë ¤ë©´ í•„ìš”í•˜ë‹ˆê¹Œ `split.py` ì‘ì„±í•˜ê¸° ì „ì— ì„¤ì¹˜í•˜ëŠ” ê²Œ ì¢‹ì•„ìš”.

==========================================================

# ì°¸ê³  ì½”ë“œ (ì½˜í…ì¸  ì¶”ì²œ ëª¨ë¸ ë§Œë“¤ê¸°)

## Dataset - watch_log

- ë°ì´í„°ì…‹ ê´€ë ¨ ê¸°ëŠ¥ êµ¬í˜„
    - **ë°ì´í„°ì…‹ ì¤€ë¹„** â†’ ëª¨ë¸ ì¤€ë¹„ â†’ í•™ìŠµ â†’ ê²€ì¦ ë° í‰ê°€ â†’ ëª¨ë¸ ì €ì¥

### ë°ì´í„°ì…‹ ì¤€ë¹„

src/dataset/watch_log.py

```
import os

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder

from src.utils.utils import project_path


class WatchLogDataset:
    def __init__(self, df, scaler=None, label_encoder=None):
        self.df = df
        self.features = None
        self.labels = None
        self.scaler = scaler
        self.label_encoder = label_encoder
        self.contents_id_map = None
        self._preprocessing()

    def _preprocessing(self):
        # content_idë¥¼ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜
        if self.label_encoder:
            self.df["content_id"] = self.label_encoder.transform(self.df["content_id"])
        else:
            self.label_encoder = LabelEncoder()
            self.df["content_id"] = self.label_encoder.fit_transform(self.df["content_id"])
        
        # content_id ë””ì½”ë”© ë§µ ìƒì„±
        self.contents_id_map = dict(enumerate(self.label_encoder.classes_))

        # íƒ€ê²Ÿ ë° í”¼ì²˜ ì •ì˜
        target_columns = ["rating", "popularity", "watch_seconds"]
        self.labels = self.df["content_id"].values
        features = self.df[target_columns].values

        # í”¼ì²˜ ìŠ¤ì¼€ì¼ë§
        if self.scaler:
            self.features = self.scaler.transform(features)
        else:
            self.scaler = StandardScaler()
            self.features = self.scaler.fit_transform(features)

    def decode_content_id(self, encoded_id):
        return self.contents_id_map[encoded_id]

    @property
    def features_dim(self):
        return self.features.shape[1]

    @property
    def num_classes(self):
        return len(self.label_encoder.classes_)

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        return self.features[idx], self.labels[idx]


def read_dataset():
    watch_log_path = os.path.join(project_path(), "dataset", "watch_log.csv")
    return pd.read_csv(watch_log_path)


def split_dataset(df):
    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)
    train_df, test_df = train_test_split(train_df, test_size=0.2, random_state=42)
    return train_df, val_df, test_df


def get_datasets(scaler=None, label_encoder=None):
    df = read_dataset()
    train_df, val_df, test_df = split_dataset(df)
    train_dataset = WatchLogDataset(train_df, scaler, label_encoder)
    val_dataset = WatchLogDataset(val_df, scaler=train_dataset.scaler, label_encoder=train_dataset.label_encoder)
    test_dataset = WatchLogDataset(test_df, scaler=train_dataset.scaler, label_encoder=train_dataset.label_encoder)
    return train_dataset, val_dataset, test_dataset

```

###Dataset - data_loader

- ë°ì´í„° ë¡œë” ê¸°ëŠ¥ êµ¬í˜„ - ML í•™ìŠµ ì‹œ í•„ìš”í•œ ë°ì´í„°ì…‹ì„ ë‹¤ì–‘í•œ í˜•íƒœë¡œ ë‹¤ë£¨ê¸° ìœ„í•œ ê¸°ëŠ¥
    - **ë°ì´í„°ì…‹ ì¤€ë¹„** â†’ ëª¨ë¸ ì¤€ë¹„ â†’ í•™ìŠµ â†’ ê²€ì¦ ë° í‰ê°€ â†’ ëª¨ë¸ ì €ì¥

### ë°ì´í„°ì…‹ ì¤€ë¹„

src/dataset/data_loader.py

```
import math

import numpy as np


class SimpleDataLoader:
    def __init__(self, features, labels, batch_size=32, shuffle=True):
        self.features = features
        self.labels = labels
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.num_samples = len(features)
        self.indices = np.arange(self.num_samples)

    def __iter__(self):
        if self.shuffle:
            np.random.shuffle(self.indices)
        self.current_idx = 0
        return self

    def __next__(self):
        if self.current_idx >= self.num_samples:
            raise StopIteration

        start_idx = self.current_idx
        end_idx = start_idx + self.batch_size
        self.current_idx = end_idx

        batch_indices = self.indices[start_idx:end_idx]
        return self.features[batch_indices], self.labels[batch_indices]
        
    def __len__(self):
        return math.ceil(self.num_samples / self.batch_size)
```

## Model

- ëª¨ë¸ ì•„í‚¤í…ì²˜ ì •ì˜ ë° í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
    - ë°ì´í„°ì…‹ ì¤€ë¹„ ****â†’ **ëª¨ë¸ ì¤€ë¹„** â†’ í•™ìŠµ â†’ ê²€ì¦ ë° í‰ê°€ â†’ ëª¨ë¸ ì €ì¥

### ëª¨ë¸ ì¤€ë¹„

src/model/movie_predictor.py

```
import numpy as np


class MoviePredictor:
    name = "movie_predictor"

    def __init__(self, input_dim, hidden_dim, num_classes):
        self.weights1 = np.random.randn(input_dim, hidden_dim) * 0.01
        self.bias1 = np.zeros((1, hidden_dim))
        self.weights2 = np.random.randn(hidden_dim, num_classes) * 0.01
        self.bias2 = np.zeros((1, num_classes))

    def relu(self, x):
        return np.maximum(0, x)

    def softmax(self, x):
        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))
        return exp_x / np.sum(exp_x, axis=1, keepdims=True)

    def forward(self, x):
        self.z1 = np.dot(x, self.weights1) + self.bias1
        self.a1 = self.relu(self.z1)
        self.z2 = np.dot(self.a1, self.weights2) + self.bias2
        self.output = self.softmax(self.z2)
        return self.output

    def backward(self, x, y, output, lr=0.001):
        m = len(x)

        dz2 = (output - y) / m
        dw2 = np.dot(self.a1.T, dz2)
        db2 = np.sum(dz2, axis=0, keepdims=True)

        da1 = np.dot(dz2, self.weights2.T)
        dz1 = da1 * (self.z1 > 0)
        dw1 = np.dot(x.T, dz1)
        db1 = np.sum(dz1, axis=0, keepdims=True)

        # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
        self.weights2 -= lr * dw2
        self.bias2 -= lr * db2
        self.weights1 -= lr * dw1
        self.bias1 -= lr * db1
```

## Training

- ëª¨ë¸ í•™ìŠµ ë£¨í”„ êµ¬í˜„
    - ë°ì´í„°ì…‹ ì¤€ë¹„ â†’ ëª¨ë¸ ì¤€ë¹„ â†’ **í•™ìŠµ** â†’ ê²€ì¦ ë° í‰ê°€ â†’ ëª¨ë¸ ì €ì¥

### í•™ìŠµ

```
import numpy as np


def train(model, train_loader):
    total_loss = 0
    for features, labels in train_loader:
        predictions = model.forward(features)
        labels = labels.reshape(-1, 1)
        loss = np.mean((predictions - labels) ** 2)
        
        model.backward(features, labels, predictions)

        total_loss += loss

    return total_loss / len(train_loader)
```

## Evaluation

- ëª¨ë¸ ì¶”ë¡  ë° í‰ê°€ ë£¨í”„ êµ¬í˜„
    - ë°ì´í„°ì…‹ ì¤€ë¹„ â†’ ëª¨ë¸ ì¤€ë¹„ â†’ í•™ìŠµ â†’ **ê²€ì¦ ë° í‰ê°€** â†’ ëª¨ë¸ ì €ì¥

### ê²€ì¦ ë° í‰ê°€

```
import numpy as np


def evaluate(model, val_loader):
    total_loss = 0
    all_predictions = []

    for features, labels in val_loader:
        predictions = model.forward(features)
        labels = labels.reshape(-1, 1)

        loss = np.mean((predictions - labels) ** 2)
        total_loss += loss * len(features)
        
        predicted = np.argmax(predictions, axis=1)
        all_predictions.extend(predicted)  # modified

    return total_loss / len(val_loader), all_predictions
```

## Main

- ë©”ì¸ ì§„ì…ì  êµ¬í˜„
    - ì „ì²´ ê³¼ì •(ë°ì´í„°ì…‹ ì¤€ë¹„ â†’ ëª¨ë¸ ì¤€ë¹„ â†’ í•™ìŠµ â†’ ê²€ì¦ ë° í‰ê°€ â†’ (ëª¨ë¸ ì €ì¥)) **ì¼ê´„ ìˆ˜í–‰**

### ì¼ê´„ ìˆ˜í–‰

```
import os
import sys

sys.path.append(
    os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
)

from src.dataset.watch_log import get_datasets
from src.dataset.data_loader import SimpleDataLoader
from src.model.movie_predictor import MoviePredictor
from src.utils.utils import init_seed
from src.train.train import train
from src.evaluate.evaluate import evaluate


init_seed()


if __name__ == '__main__':
    # ë°ì´í„°ì…‹ ë° DataLoader ìƒì„±
    train_dataset, val_dataset, test_dataset = get_datasets()
    train_loader = SimpleDataLoader(train_dataset.features, train_dataset.labels, batch_size=64, shuffle=True)
    val_loader = SimpleDataLoader(val_dataset.features, val_dataset.labels, batch_size=64, shuffle=False)
    test_loader = SimpleDataLoader(test_dataset.features, test_dataset.labels, batch_size=64, shuffle=False)

    # ëª¨ë¸ ì´ˆê¸°í™”
    model_params = {
        "input_dim": train_dataset.features_dim,
        "num_classes": train_dataset.num_classes,
        "hidden_dim": 64
    }
    model = MoviePredictor(**model_params)

    # í•™ìŠµ ë£¨í”„
    num_epochs = 10
    for epoch in range(num_epochs):
        train_loss = train(model, train_loader)
        val_loss, _ = evaluate(model, val_loader)
        print(f"Epoch {epoch + 1}/{num_epochs}, "
              f"Train Loss: {train_loss:.4f}, "
              f"Val Loss: {val_loss:.4f}, "
              f"Val-Train Loss : {val_loss-train_loss:.4f}")

    # í…ŒìŠ¤íŠ¸
    test_loss, predictions = evaluate(model, test_loader)
    print(f"Test Loss : {test_loss:.4f}")
    print([train_dataset.decode_content_id(idx) for idx in predictions])
```


## ëª¨ë¸ ì €ì¥í•˜ê¸°

### pickle(pkl), torch(pth) í¬ë§·ìœ¼ë¡œ ì €ì¥í•˜ê¸°

- ë°ì´í„°ì…‹ ì¤€ë¹„ â†’ ëª¨ë¸ ì¤€ë¹„ â†’ í•™ìŠµ â†’ ê²€ì¦ ë° í‰ê°€ â†’ **ëª¨ë¸ ì €ì¥**

src/model/movie_predictor.py

```
import os
import pickle
import datetime

from src.utils.utils import model_dir


def model_save(model, model_params, epoch, loss, scaler, label_encoder):
    save_dir = model_dir(model.name)
    os.makedirs(save_dir, exist_ok=True)

    current_time = datetime.datetime.now().strftime("%y%m%d%H%M%S")
    dst = os.path.join(save_dir, f"E{epoch}_T{current_time}.pkl")

    save_data = {
        "epoch": epoch,
        "model_params": model_params,
        "model_state_dict": {
            "weights1": model.weights1,
            "bias1": model.bias1,
            "weights2": model.weights2,
            "bias2": model.bias2,
        },
        "loss": loss,
        "scaler": scaler,
        "label_encoder": label_encoder,
    }

    # ë°ì´í„° ì €ì¥
    with open(dst, "wb") as f:
        pickle.dump(save_data, f)

    print(f"Model saved to {dst}")
```

## Fire ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•œ íƒœìŠ¤í¬ ë¶„ë¦¬ ë° íŒŒë¼ë¯¸í„°í™”

- Fire ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•˜ë©´ íƒœìŠ¤í¬ë³„ë¡œ í•„ìš”í•œ ì¸ìë¥¼ ì„¤ì •í•˜ì—¬ CLI ê¸°ë°˜ í”„ë¡œê·¸ë¨ì„ ì‰½ê³  ë¹ ë¥´ê²Œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- íƒœìŠ¤í¬ë¥¼ ë¶„ë¦¬í•˜ë©´ ë‹¤ì–‘í•œ ì¥ì ì´ ìˆìŠµë‹ˆë‹¤.(í•„ìš”í•œ íƒœìŠ¤í¬ë§Œ ìˆ˜í–‰, íŠ¸ëŸ¬ë¸” ìŠˆíŒ… ë° ë””ë²„ê¹… ìš©ì´, ìœ ì—°í•œ ìì› í• ë‹¹, ìœ ì§€ë³´ìˆ˜ì„±, ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ ë“±)



------------

**Fireë¥¼ ì‚¬ìš©í•˜ë©´ ë‹¤ì–‘í•œ ì‹¤í—˜ ì„¤ì •ìœ¼ë¡œ ëª¨ë¸ì„ ì‹¤í–‰í•  ìˆ˜ ìˆì–´ìš”!** ğŸ”¥

**ê¸°ë³¸ ì‚¬ìš©ë²•:**

**1. ê¸°ë³¸ ì‹¤í–‰ (ëª¨ë“  ê¸°ë³¸ê°’ ì‚¬ìš©):**
```bash
docker exec -it mlops-cloud-project-mlops-7-jupyter-1 bash -c "python /app/src/models/train.py"
```

**2. íŠ¹ì • ëª¨ë¸ë“¤ë§Œ í•™ìŠµ:**
```bash
# Random Forestì™€ XGBoostë§Œ
docker exec -it mlops-cloud-project-mlops-7-jupyter-1 bash -c "python /app/src/models/train.py --model_names='[\"rf\", \"xgb\"]'"

# ì„ í˜• ëª¨ë¸ë“¤ë§Œ
docker exec -it mlops-cloud-project-mlops-7-jupyter-1 bash -c "python /app/src/models/train.py --model_names='[\"linear\", \"ridge\", \"lasso\"]'"
```

**3. ë°ì´í„° ë¶„í•  ë¹„ìœ¨ ì¡°ì •:**
```bash
# í…ŒìŠ¤íŠ¸ 30%, ê²€ì¦ 15%ë¡œ ì„¤ì •
docker exec -it mlops-cloud-project-mlops-7-jupyter-1 bash -c "python /app/src/models/train.py --test_size=0.3 --val_size=0.15"
```

**4. ëœë¤ ì‹œë“œ ë³€ê²½:**
```bash
# ë‹¤ë¥¸ ì‹œë“œë¡œ ì‹¤í—˜
docker exec -it mlops-cloud-project-mlops-7-jupyter-1 bash -c "python /app/src/models/train.py --random_state=123"
```

**5. ë³µí•© ì‹¤í—˜:**
```bash
# íŠ¸ë¦¬ ëª¨ë¸ë§Œ, í° í…ŒìŠ¤íŠ¸ì…‹, ë‹¤ë¥¸ ì‹œë“œ
docker exec -it mlops-cloud-project-mlops-7-jupyter-1 bash -c "python /app/src/models/train.py --model_names='[\"rf\", \"xgb\", \"lgbm\", \"cat\"]' --test_size=0.25 --random_state=999"
```

**ì‹¤í—˜ ì˜ˆì‹œë“¤:**
```bash
docker exec -it mlops-cloud-project-mlops-7-jupyter-1 bash -c "python /app/src/models/train.py --model_names='[\"rf\", \"xgb\"]' --test_size=0.25"
```


**ë„¤, ë§ìŠµë‹ˆë‹¤!** ğŸ¯

**Fireë¡œ ë‹¤ë¥¸ ì„¤ì •ìœ¼ë¡œ ì‹¤í–‰í•˜ë©´ ìƒˆë¡œìš´ ì‹¤í—˜ ë²ˆí˜¸ë¡œ ì €ì¥ë©ë‹ˆë‹¤:**

- **ì²« ë²ˆì§¸ ì‹¤í–‰**: `weather-predictor-001` âœ… (ì´ë¯¸ ì™„ë£Œ)
- **ë‘ ë²ˆì§¸ ì‹¤í–‰**: `weather-predictor-002` 
- **ì„¸ ë²ˆì§¸ ì‹¤í–‰**: `weather-predictor-003`
- **...ê³„ì† ì¦ê°€**

**ì˜ˆë¥¼ ë“¤ì–´:**
```bash
# ì´ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ë©´
docker exec -it mlops-cloud-project-mlops-7-jupyter-1 bash -c "python /app/src/models/train.py --model_names='[\"rf\", \"xgb\"]'"

# ê²°ê³¼:
# - WANDB: weather-predictor-002 ì‹¤í—˜ìœ¼ë¡œ ê¸°ë¡
# - S3: s3://weather-mlops-team-data/models/weather-predictor-002/ ì— ì €ì¥
```

**ì´ë ‡ê²Œ ë˜ëŠ” ì´ìœ :**
- `utils.py`ì˜ `auto_increment_run_suffix("weather-predictor")` í•¨ìˆ˜ê°€ ìë™ìœ¼ë¡œ ë²ˆí˜¸ë¥¼ ì¦ê°€ì‹œí‚´
- ë§¤ë²ˆ ì‹¤í–‰í•  ë•Œë§ˆë‹¤ ìƒˆë¡œìš´ ì‹¤í—˜ìœ¼ë¡œ ê´€ë¦¬ë¨

**ì¥ì :**
- ğŸ”„ **ì‹¤í—˜ ë²„ì „ ê´€ë¦¬** - ê° ì‹¤í—˜ì´ ë…ë¦½ì ìœ¼ë¡œ ì €ì¥
- ğŸ“Š **ì„±ëŠ¥ ë¹„êµ** - WANDBì—ì„œ 002 vs 001 ì„±ëŠ¥ ë¹„êµ ê°€ëŠ¥  
- ğŸ’¾ **ëª¨ë¸ ë³´ê´€** - ê° ì‹¤í—˜ì˜ ìµœê³  ëª¨ë¸ì´ ë³„ë„ ì €ì¥
- ğŸš€ **ì¬í˜„ ê°€ëŠ¥ì„±** - ì–¸ì œë“  íŠ¹ì • ì‹¤í—˜ ì„¤ì •ìœ¼ë¡œ ëŒì•„ê°ˆ ìˆ˜ ìˆìŒ

**ì‹¤í—˜í•´ë³´ê³  ì‹¶ìœ¼ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”!** ì–´ë–¤ ì„¤ì •ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•´ë³¼ê¹Œìš”? ğŸ¤”



**ì¼ë°˜ì ì¸ MLOps ì‹¤í—˜ ê´€ë¦¬ ë°©ì‹ì€ ì´ë ‡ìŠµë‹ˆë‹¤:**

**ğŸ”„ ì‹¤í—˜ ê´€ë¦¬ íŒ¨í„´:**

**1. ê°œë°œ/íƒìƒ‰ ë‹¨ê³„:**
- ë‹¤ì–‘í•œ ì„¤ì •ìœ¼ë¡œ ì—¬ëŸ¬ ì‹¤í—˜ ì‹¤í–‰
- ì„±ëŠ¥ ë¹„êµí•˜ì—¬ ìµœì  ì„¤ì • ì°¾ê¸°
- ê° ì‹¤í—˜ì€ ë³„ë„ ë²„ì „ìœ¼ë¡œ ì €ì¥

**2. í”„ë¡œë•ì…˜ ë‹¨ê³„:**
- ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì„ "ìš´ì˜ ëª¨ë¸"ë¡œ ì„ íƒ
- í•´ë‹¹ ëª¨ë¸ë§Œ ì‹¤ì œ ì„œë¹„ìŠ¤ì— ë°°í¬

**ì¼ë°˜ì ì¸ ì‹¤í—˜ ì›Œí¬í”Œë¡œìš°:**

```bash
# ì‹¤í—˜ 1: ëª¨ë“  ëª¨ë¸ ë¹„êµ (ê¸°ë³¸)
python train.py  # â†’ weather-predictor-001

# ì‹¤í—˜ 2: íŠ¸ë¦¬ ëª¨ë¸ë§Œ ì§‘ì¤‘ ë¶„ì„
python train.py --model_names='["rf", "xgb", "lgbm", "cat"]'  # â†’ 002

# ì‹¤í—˜ 3: ë°ì´í„° ë¶„í•  ë¹„ìœ¨ ë³€ê²½
python train.py --test_size=0.3 --val_size=0.15  # â†’ 003

# ì‹¤í—˜ 4: íŠ¹ì • ì‹œë“œë¡œ ì¬í˜„ì„± í™•ì¸
python train.py --random_state=999  # â†’ 004
```

**ğŸ¯ ëª©ì ë³„ ì‹¤í—˜:**
- **ë² ì´ìŠ¤ë¼ì¸**: ëª¨ë“  ëª¨ë¸ë¡œ ì „ì²´ ì„±ëŠ¥ íŒŒì•…
- **ëª¨ë¸ ì„ íƒ**: íŠ¹ì • ëª¨ë¸êµ° ì§‘ì¤‘ ë¶„ì„  
- **ë°ì´í„° ë¯¼ê°ë„**: ë¶„í•  ë¹„ìœ¨ ë³€ê²½ ì‹¤í—˜
- **ì¬í˜„ì„±**: ë‹¤ë¥¸ ì‹œë“œë¡œ ì•ˆì •ì„± í™•ì¸

**ğŸ’¡ ì‹¤ì œ ì—…ë¬´ì—ì„œëŠ”:**
- 10-20ê°œ ì‹¤í—˜ í›„ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ
- í•´ë‹¹ ëª¨ë¸ì„ API ì„œë²„ì— ë°°í¬
- ì •ê¸°ì ìœ¼ë¡œ ìƒˆ ë°ì´í„°ë¡œ ì¬í•™ìŠµ

**ì–´ë–¤ ì‹¤í—˜ì„ í•´ë³´ê³  ì‹¶ìœ¼ì„¸ìš”?** ğŸ¤”

--------
**ë„¤, ì •í™•íˆ ë§ìŠµë‹ˆë‹¤!** ğŸ‘

**ì‹¤ì œ ì›Œí¬í”Œë¡œìš°:**

**1. ì‹¤í—˜ ëˆ„ì :**
- 001: ì „ì²´ ëª¨ë¸ ë¹„êµ â†’ Val RMSE 2.54
- 002: íŠ¸ë¦¬ ëª¨ë¸ë§Œ â†’ Val RMSE 2.48  
- 003: ë°ì´í„° ë¶„í•  ë³€ê²½ â†’ Val RMSE 2.51
- 004: ë‹¤ë¥¸ ì‹œë“œ â†’ Val RMSE 2.52
- 005: íŠ¹ì • í•˜ì´í¼íŒŒë¼ë¯¸í„° â†’ Val RMSE **2.31** â­
- 006: ë˜ ë‹¤ë¥¸ ì„¤ì • â†’ Val RMSE 2.45
- ...
- 010: ë§ˆì§€ë§‰ ì‹¤í—˜ â†’ Val RMSE 2.38

**2. WANDBì—ì„œ ì „ì²´ ë¹„êµ:**
- 001~010 ëª¨ë“  ì‹¤í—˜ì„ í…Œì´ë¸”ë¡œ ì •ë ¬
- `best_val_rmse` ê¸°ì¤€ìœ¼ë¡œ ìˆœìœ„ ë§¤ê¹€
- **005ë²ˆì´ 2.31ë¡œ ìµœê³  ì„±ëŠ¥** í™•ì¸

**3. ìµœì¢… ê²°ì •:**
**"005ë²ˆ ëª¨ë¸(`weather-predictor-005`)ì„ í”„ë¡œë•ì…˜ì— ì‚¬ìš©í•˜ì„¸ìš”"**

**4. ì‹¤ì œ ì‚¬ìš©:**
```bash
# S3ì—ì„œ 005ë²ˆ ëª¨ë¸ ë¡œë“œ
s3://weather-mlops-team-data/models/weather-predictor-005/model_artifact/model.pkl
```

**ğŸ’¡ í•µì‹¬:**
- **ì‹¤í—˜ì€ ê³„ì† ìŒ“ì„** (001~010...)
- **ì„±ëŠ¥ ë¹„êµ í›„ ìµœê³  ë²„ì „ ì„ íƒ** (005)
- **ë‚˜ë¨¸ì§€ëŠ” ë°±ì—…ìš©ìœ¼ë¡œ ë³´ê´€** (ë¡¤ë°± ê°€ëŠ¥)
- **ìƒˆë¡œìš´ ì‹¤í—˜ì€ 011ë¶€í„° ê³„ì†**

**ë°”ë¡œ ì´ëŸ° ë°©ì‹ì´ ë§ìŠµë‹ˆë‹¤!** ğŸ¯

---

**í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì€ ë³´í†µ ì´ ë‹¨ê³„ì—ì„œ í•©ë‹ˆë‹¤!** ğŸ¯

**ğŸ“ˆ ì‹¤í—˜ ìˆœì„œ (ì¼ë°˜ì ì¸ MLOps ì›Œí¬í”Œë¡œìš°):**

**1ë‹¨ê³„: ë² ì´ìŠ¤ë¼ì¸ ì„¤ì •** âœ… (ì™„ë£Œ)
- ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ëª¨ë“  ëª¨ë¸ ë¹„êµ
- ì–´ë–¤ ëª¨ë¸ì´ ê°€ì¥ ìœ ë§í•œì§€ íŒŒì•…

**2ë‹¨ê³„: ë°ì´í„°/ì„¤ì • ì‹¤í—˜** (ì§€ê¸ˆ ë‹¨ê³„)
- ë°ì´í„° ë¶„í•  ë¹„ìœ¨ ë³€ê²½
- í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì‹¤í—˜
- ì „ì²˜ë¦¬ ë°©ë²• ë³€ê²½

**3ë‹¨ê³„: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹** â­ (ë‹¤ìŒ ë‹¨ê³„)
- **ìœ ë§í•œ ëª¨ë¸ 1-2ê°œë§Œ ì„ íƒ** (RF, XGB ë“±)
- ê° ëª¨ë¸ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
- GridSearch, RandomSearch, Optuna ë“± ì‚¬ìš©

**4ë‹¨ê³„: ì•™ìƒë¸”/ê³ ê¸‰ ê¸°ë²•**
- ìµœê³  ëª¨ë¸ë“¤ ì•™ìƒë¸”
- ìŠ¤íƒœí‚¹, ë¸”ë Œë”© ë“±

**ğŸ”§ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì :**
- **í˜„ì¬**: RFê°€ ìµœê³  ì„±ëŠ¥ (2.54 RMSE)
- **ë‹¤ìŒ**: RFì˜ `n_estimators`, `max_depth`, `min_samples_split` ë“± íŠœë‹
- **ê·¸ ë‹¤ìŒ**: XGBì˜ `learning_rate`, `max_depth`, `n_estimators` ë“± íŠœë‹

**ğŸ’¡ ì´ìœ :**
- ëª¨ë“  ëª¨ë¸ì„ íŠœë‹í•˜ë©´ ì‹œê°„ì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦¼
- ìœ ë§í•œ ëª¨ë¸ë§Œ ì§‘ì¤‘ íˆ¬ìí•˜ëŠ” ê²Œ íš¨ìœ¨ì 
- ë² ì´ìŠ¤ë¼ì¸ ëŒ€ë¹„ ì–¼ë§ˆë‚˜ ê°œì„ ë˜ëŠ”ì§€ ì¸¡ì • ê°€ëŠ¥

**ì§€ê¸ˆì€ 2-3ê°œ ê¸°ë³¸ ì‹¤í—˜ ë” í•˜ê³ , ê·¸ ë‹¤ìŒì— í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹í•˜ëŠ” ê²Œ ì¢‹ê² ì–´ìš”!** ğŸš€

