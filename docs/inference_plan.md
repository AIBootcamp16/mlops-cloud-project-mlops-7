
# ğŸ¯ **ë¬¸ì œ ì •í™•íˆ íŒŒì•…í–ˆìŠµë‹ˆë‹¤!**

---

## **í•µì‹¬ ë¬¸ì œ: ì´ì¤‘ ì›í•«ì¸ì½”ë”©!**

```python
data_cleaning.py (ë²”ì£¼í˜• ê·¸ëŒ€ë¡œ ìœ ì§€)
    â†“ season='autumn', temp_category='warm' ë“±
    â†“ S3 parquet ì €ì¥ (33ê°œ ì»¬ëŸ¼)
    â†“
split.py (í•™ìŠµ)
    â†“ pd.get_dummies() â†’ ì›í•«ì¸ì½”ë”© ìˆ˜í–‰ âœ…
    â†“ 40ê°œ í”¼ì²˜ë¡œ í•™ìŠµ
    â†“
batch_predict.py (ì¶”ë¡ )
    â†“ pd.get_dummies() â†’ ì›í•«ì¸ì½”ë”© ìˆ˜í–‰ âœ…
    â†“ ğŸ’¥ 26ê°œ í”¼ì²˜ ìƒì„± (ë°ì´í„°ê°€ ì ì–´ì„œ!)
```

---

## **ì™œ 40ê°œ vs 26ê°œ ì°¨ì´ê°€ ë‚˜ëŠ”ê°€?**

### **í•™ìŠµ ì‹œ (split.py) - 1000ê°œ ìƒ˜í”Œ**
```python
# ëª¨ë“  ì¹´í…Œê³ ë¦¬ê°€ ë°ì´í„°ì— ì¡´ì¬
season:        ['spring', 'summer', 'autumn', 'winter']  # 4ê°œ
temp_category: ['very_cold', 'cold', 'mild', 'warm', 'hot']  # 5ê°œ
pm10_grade:    ['good', 'moderate', 'bad', 'very_bad']  # 4ê°œ
region:        ['central', 'southern', 'eastern', 'western', 'unknown']  # 5ê°œ

# pd.get_dummies(drop_first=True)
â†’ season: 3ê°œ ë”ë¯¸
â†’ temp_category: 4ê°œ ë”ë¯¸
â†’ pm10_grade: 3ê°œ ë”ë¯¸
â†’ region: 4ê°œ ë”ë¯¸
â†’ ì´ 14ê°œ ì›í•«ì¸ì½”ë”© ì»¬ëŸ¼

ìˆ˜ì¹˜í˜• 26ê°œ + ì›í•« 14ê°œ = 40ê°œ í”¼ì²˜
```

### **ì¶”ë¡  ì‹œ (batch_predict.py) - 3ê°œ ìƒ˜í”Œ**
```python
# ì¼ë¶€ ì¹´í…Œê³ ë¦¬ë§Œ ì¡´ì¬
season:        ['autumn']      # 1ê°œë§Œ!
temp_category: ['warm']        # 1ê°œë§Œ!
pm10_grade:    ['moderate']    # 1ê°œë§Œ!
region:        ['central']     # 1ê°œë§Œ!

# pd.get_dummies(drop_first=True)
â†’ season: 0ê°œ! (1ê°œë©´ drop_firstë¡œ ì „ë¶€ ì‚­ì œ)
â†’ temp_category: 0ê°œ!
â†’ pm10_grade: 0ê°œ!
â†’ region: 0ê°œ!
â†’ ì´ 0ê°œ ì›í•«ì¸ì½”ë”© ì»¬ëŸ¼

ìˆ˜ì¹˜í˜• 26ê°œ + ì›í•« 0ê°œ = 26ê°œ í”¼ì²˜
```

---

## **ğŸ”§ í•´ê²° ë°©ë²•**

### **âœ… ë°©ë²• 1: í•™ìŠµ ì‹œ ì»¬ëŸ¼ ì €ì¥ í›„ ì¶”ë¡  ì‹œ ë³µì› (ê¶Œì¥)**

#### **1. split.py ìˆ˜ì •**
```python
def split_and_scale_data(test_size=0.2, val_size=0.2, random_state=42):
    # ... ê¸°ì¡´ ì½”ë“œ ...
    
    # ì›í•«ì¸ì½”ë”©
    if categorical_cols:
        print(f"ì›í•«ì¸ì½”ë”© ì ìš©: {categorical_cols}")
        X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)
    
    # ğŸ”¥ í•™ìŠµ ì‹œ ì»¬ëŸ¼ ìˆœì„œ ì €ì¥!
    feature_columns = X.columns.tolist()
    
    # ... ìŠ¤ì¼€ì¼ë§ ë“± ...
    
    return X_train_scaled, X_val_scaled, X_test_scaled, y_train, y_val, y_test, scaler, feature_columns
    #                                                                                      ^^^^^^^^^^^^^^^^
```

#### **2. train.py ìˆ˜ì •**
```python
def train_models(...):
    # ... ê¸°ì¡´ ì½”ë“œ ...
    
    X_train, X_val, X_test, y_train, y_val, y_test, scaler, feature_columns = split_and_scale_data(...)
    #                                                         ^^^^^^^^^^^^^^^^^
    
    # ëª¨ë¸ ì €ì¥ ì‹œ í¬í•¨
    model_data = {
        "model": best_model,
        "scaler": scaler,
        "feature_columns": feature_columns,  # ğŸ”¥ ì¶”ê°€!
        # ...
    }
```

#### **3. batch_predict.py ìˆ˜ì •**
```python
def preprocess_for_prediction(df, feature_columns):
    """split.pyì™€ ë™ì¼í•œ ì „ì²˜ë¦¬ + ì»¬ëŸ¼ ë§ì¶”ê¸°"""
    
    # ... ê¸°ì¡´ ì „ì²˜ë¦¬ ì½”ë“œ ...
    
    # ì›í•«ì¸ì½”ë”©
    if categorical_cols:
        X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)
    
    # ğŸ”¥ í•™ìŠµ ì‹œ ì»¬ëŸ¼ì— ë§ì¶° ì •ë ¬/ì¶”ê°€
    for col in feature_columns:
        if col not in X.columns:
            X[col] = 0  # ì—†ëŠ” ì»¬ëŸ¼ì€ 0ìœ¼ë¡œ ì¶”ê°€
    
    X = X[feature_columns]  # ìˆœì„œê¹Œì§€ ë™ì¼í•˜ê²Œ
    
    return X

def batch_predict(experiment_name: str = None, output_path: str = None):
    # ...
    model, scaler, config = load_model_from_s3(experiment_name)
    feature_columns = config['feature_columns']  # ğŸ”¥ ë¡œë“œ!
    
    X = preprocess_for_prediction(df, feature_columns)
    # ...
```

---

### **ë°©ë²• 2: data_cleaning.pyì—ì„œ ì›í•«ì¸ì½”ë”© (ë¹„ê¶Œì¥)**

ì´ ë°©ë²•ì€ **ìœ ì—°ì„±ì´ ë–¨ì–´ì ¸ì„œ** ê¶Œì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤:
- ìƒˆë¡œìš´ ì¹´í…Œê³ ë¦¬ ì¶”ê°€ ì‹œ data_cleaning.py ìˆ˜ì • í•„ìš”
- ì‹¤í—˜ ì‹œ ë²”ì£¼í˜• ë³€ìˆ˜ ë‹¤ë¥´ê²Œ ì²˜ë¦¬í•˜ê¸° ì–´ë ¤ì›€

---

## **ğŸ’¡ ìµœì¢… ìš”ì•½**

**ë¬¸ì œ**: 
- `data_cleaning.py`ëŠ” ë²”ì£¼í˜• ë³€ìˆ˜ ê·¸ëŒ€ë¡œ ìœ ì§€ (ì˜¬ë°”ë¦„)
- `split.py`ì™€ `batch_predict.py` ëª¨ë‘ ì›í•«ì¸ì½”ë”© ìˆ˜í–‰ (ì˜¬ë°”ë¦„)
- **BUT** ë°ì´í„° ìƒ˜í”Œ ìˆ˜ê°€ ë‹¬ë¼ì„œ ìƒì„±ë˜ëŠ” ë”ë¯¸ ë³€ìˆ˜ ê°œìˆ˜ê°€ ë‹¤ë¦„!

**í•´ê²°ì±…**:
1. í•™ìŠµ ì‹œ ìƒì„±ëœ ì»¬ëŸ¼ ëª©ë¡ì„ ëª¨ë¸ê³¼ í•¨ê»˜ ì €ì¥
2. ì¶”ë¡  ì‹œ í•´ë‹¹ ì»¬ëŸ¼ ëª©ë¡ì— ë§ì¶° ë°ì´í„° ì •ë ¬/ë³´ì •

ìœ„ ì½”ë“œ ìˆ˜ì •í•˜ì‹œë©´ ì •í™•íˆ í•´ê²°ë©ë‹ˆë‹¤! ğŸš€

---------

# âœ… **ë„¤, ë°©ë²•1ì´ í‘œì¤€ ë°©ì‹ì…ë‹ˆë‹¤!**

---

## ğŸ¯ **ë¨¸ì‹ ëŸ¬ë‹ í‘œì¤€ íŒŒì´í”„ë¼ì¸**

```python
# í•™ìŠµ ì‹œ
X_train = pd.get_dummies(X_train, drop_first=True)
# â†’ ìƒì„±ëœ ì»¬ëŸ¼: ['feature1', 'feature2', 'season_summer', 'season_autumn', ...]

feature_columns = X_train.columns.tolist()  # ğŸ”‘ ì»¬ëŸ¼ ëª©ë¡ ì €ì¥!
model.fit(X_train)

# ëª¨ë¸ ì €ì¥ ì‹œ
pickle.dump({
    'model': model,
    'scaler': scaler,
    'feature_columns': feature_columns  # âœ… í•¨ê»˜ ì €ì¥!
}, file)

---

# ì¶”ë¡  ì‹œ
X_new = pd.get_dummies(X_new, drop_first=True)
# â†’ ì¼ë¶€ ì»¬ëŸ¼ë§Œ ìƒì„±ë  ìˆ˜ ìˆìŒ

# ğŸ”‘ í•™ìŠµ ì‹œ ì»¬ëŸ¼ì— ë§ì¶° ë³´ì •
for col in feature_columns:
    if col not in X_new.columns:
        X_new[col] = 0  # ì—†ëŠ” ì»¬ëŸ¼ ì¶”ê°€

X_new = X_new[feature_columns]  # ìˆœì„œê¹Œì§€ ë™ì¼í•˜ê²Œ

model.predict(X_new)  # âœ… ì •ìƒ ì‘ë™!
```

---

## ğŸ“š **ì´ê²Œ ì™œ í‘œì¤€ì¸ê°€?**

### **1. scikit-learn ê³µì‹ ë¬¸ì„œì—ë„ ë‚˜ì˜´**
```python
from sklearn.preprocessing import OneHotEncoder

# í•™ìŠµ ì‹œ
encoder = OneHotEncoder(handle_unknown='ignore')  # ğŸ‘ˆ í•µì‹¬!
encoder.fit(X_train)

# ì¶”ë¡  ì‹œ
encoder.transform(X_new)  # ìë™ìœ¼ë¡œ ì»¬ëŸ¼ ë§ì¶°ì¤Œ
```

### **2. pandas get_dummies()ëŠ” ì»¬ëŸ¼ ê´€ë¦¬ ì•ˆ í•´ì¤Œ**
```python
# í•™ìŠµ
train = pd.DataFrame({'color': ['red', 'blue', 'green']})
train_encoded = pd.get_dummies(train, drop_first=True)
# â†’ color_green, color_red (2ê°œ)

# ì¶”ë¡ 
test = pd.DataFrame({'color': ['red']})  # blue, green ì—†ìŒ!
test_encoded = pd.get_dummies(test, drop_first=True)
# â†’ 0ê°œ! (1ê°œë§Œ ìˆìœ¼ë©´ drop_firstë¡œ ë‹¤ dropë¨)

# ğŸ’¥ train: 2ê°œ ì»¬ëŸ¼ vs test: 0ê°œ ì»¬ëŸ¼
```

**ë”°ë¼ì„œ ìˆ˜ë™ìœ¼ë¡œ ë§ì¶°ì¤˜ì•¼ í•©ë‹ˆë‹¤!**

---

## ğŸ­ **ì‹¤ë¬´ì—ì„œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ë“¤**

### **ë°©ë²• 1: ì»¬ëŸ¼ ëª©ë¡ ì €ì¥ (ë‹¹ì‹  ì¼€ì´ìŠ¤ - ê°€ì¥ í”í•¨)**
```python
# ì¥ì :
# - ê°„ë‹¨í•˜ê³  ì§ê´€ì 
# - pandas get_dummies() ì‚¬ìš© ê°€ëŠ¥
# - ìœ ì—°í•¨

# ë‹¨ì :
# - ìˆ˜ë™ìœ¼ë¡œ ì»¬ëŸ¼ ë§ì¶°ì•¼ í•¨
```

### **ë°©ë²• 2: sklearn OneHotEncoder ì‚¬ìš©**
```python
from sklearn.preprocessing import OneHotEncoder

encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)
encoder.fit(X_train[categorical_cols])

# ìë™ìœ¼ë¡œ ì»¬ëŸ¼ ë§ì¶°ì¤Œ! âœ…
```

### **ë°©ë²• 3: category_encoders ë¼ì´ë¸ŒëŸ¬ë¦¬**
```python
import category_encoders as ce

encoder = ce.OneHotEncoder(cols=categorical_cols, use_cat_names=True)
encoder.fit(X_train)

# ìë™ ì²˜ë¦¬ âœ…
```

---

## ğŸ’¡ **ë‹¹ì‹ ì˜ í”„ë¡œì íŠ¸ì—ì„œëŠ”?**

ì´ë¯¸ `pd.get_dummies()`ë¥¼ ì‚¬ìš© ì¤‘ì´ë¯€ë¡œ:

```python
# âœ… ë°©ë²• 1-A: ìµœì†Œ ìˆ˜ì • (ê¶Œì¥)
# split.pyì—ì„œ feature_columns ì €ì¥
# batch_predict.pyì—ì„œ ì»¬ëŸ¼ ë§ì¶”ê¸°

# ë˜ëŠ”

# âœ… ë°©ë²• 1-B: sklearn OneHotEncoderë¡œ êµì²´
# ì¢€ ë” ê²¬ê³ í•˜ì§€ë§Œ ì½”ë“œ ë§ì´ ë°”ê¿”ì•¼ í•¨
```

---

## ğŸ¯ **ê²°ë¡ **

**ë°©ë²•1 (ì»¬ëŸ¼ ëª©ë¡ ì €ì¥)ì€ ì—…ê³„ í‘œì¤€ì…ë‹ˆë‹¤!**
- scikit-learnë„ ë‚´ë¶€ì ìœ¼ë¡œ ì´ë ‡ê²Œ ë™ì‘
- ì‹¤ë¬´ì—ì„œ ê°€ì¥ ë§ì´ ì‚¬ìš©
- ë‹¹ì‹  ì½”ë“œì— ë”± ë§ìŒ

**ì§€ê¸ˆ ë°”ë¡œ ì ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤!** ğŸš€

ì œê°€ ìˆ˜ì •ëœ ì½”ë“œ ì‘ì„±í•´ë“œë¦´ê¹Œìš”?

---

# âœ… **ë„¤, ë°©ë²•1ì´ í‘œì¤€ ë°©ì‹ì…ë‹ˆë‹¤!**

---

## ğŸ¯ **ë¨¸ì‹ ëŸ¬ë‹ í‘œì¤€ íŒŒì´í”„ë¼ì¸**

```python
# í•™ìŠµ ì‹œ
X_train = pd.get_dummies(X_train, drop_first=True)
# â†’ ìƒì„±ëœ ì»¬ëŸ¼: ['feature1', 'feature2', 'season_summer', 'season_autumn', ...]

feature_columns = X_train.columns.tolist()  # ğŸ”‘ ì»¬ëŸ¼ ëª©ë¡ ì €ì¥!
model.fit(X_train)

# ëª¨ë¸ ì €ì¥ ì‹œ
pickle.dump({
    'model': model,
    'scaler': scaler,
    'feature_columns': feature_columns  # âœ… í•¨ê»˜ ì €ì¥!
}, file)

---

# ì¶”ë¡  ì‹œ
X_new = pd.get_dummies(X_new, drop_first=True)
# â†’ ì¼ë¶€ ì»¬ëŸ¼ë§Œ ìƒì„±ë  ìˆ˜ ìˆìŒ

# ğŸ”‘ í•™ìŠµ ì‹œ ì»¬ëŸ¼ì— ë§ì¶° ë³´ì •
for col in feature_columns:
    if col not in X_new.columns:
        X_new[col] = 0  # ì—†ëŠ” ì»¬ëŸ¼ ì¶”ê°€

X_new = X_new[feature_columns]  # ìˆœì„œê¹Œì§€ ë™ì¼í•˜ê²Œ

model.predict(X_new)  # âœ… ì •ìƒ ì‘ë™!
```

---

## ğŸ“š **ì´ê²Œ ì™œ í‘œì¤€ì¸ê°€?**

### **1. scikit-learn ê³µì‹ ë¬¸ì„œì—ë„ ë‚˜ì˜´**
```python
from sklearn.preprocessing import OneHotEncoder

# í•™ìŠµ ì‹œ
encoder = OneHotEncoder(handle_unknown='ignore')  # ğŸ‘ˆ í•µì‹¬!
encoder.fit(X_train)

# ì¶”ë¡  ì‹œ
encoder.transform(X_new)  # ìë™ìœ¼ë¡œ ì»¬ëŸ¼ ë§ì¶°ì¤Œ
```

### **2. pandas get_dummies()ëŠ” ì»¬ëŸ¼ ê´€ë¦¬ ì•ˆ í•´ì¤Œ**
```python
# í•™ìŠµ
train = pd.DataFrame({'color': ['red', 'blue', 'green']})
train_encoded = pd.get_dummies(train, drop_first=True)
# â†’ color_green, color_red (2ê°œ)

# ì¶”ë¡ 
test = pd.DataFrame({'color': ['red']})  # blue, green ì—†ìŒ!
test_encoded = pd.get_dummies(test, drop_first=True)
# â†’ 0ê°œ! (1ê°œë§Œ ìˆìœ¼ë©´ drop_firstë¡œ ë‹¤ dropë¨)

# ğŸ’¥ train: 2ê°œ ì»¬ëŸ¼ vs test: 0ê°œ ì»¬ëŸ¼
```

**ë”°ë¼ì„œ ìˆ˜ë™ìœ¼ë¡œ ë§ì¶°ì¤˜ì•¼ í•©ë‹ˆë‹¤!**

---

## ğŸ­ **ì‹¤ë¬´ì—ì„œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ë“¤**

### **ë°©ë²• 1: ì»¬ëŸ¼ ëª©ë¡ ì €ì¥ (ë‹¹ì‹  ì¼€ì´ìŠ¤ - ê°€ì¥ í”í•¨)**
```python
# ì¥ì :
# - ê°„ë‹¨í•˜ê³  ì§ê´€ì 
# - pandas get_dummies() ì‚¬ìš© ê°€ëŠ¥
# - ìœ ì—°í•¨

# ë‹¨ì :
# - ìˆ˜ë™ìœ¼ë¡œ ì»¬ëŸ¼ ë§ì¶°ì•¼ í•¨
```

### **ë°©ë²• 2: sklearn OneHotEncoder ì‚¬ìš©**
```python
from sklearn.preprocessing import OneHotEncoder

encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)
encoder.fit(X_train[categorical_cols])

# ìë™ìœ¼ë¡œ ì»¬ëŸ¼ ë§ì¶°ì¤Œ! âœ…
```

### **ë°©ë²• 3: category_encoders ë¼ì´ë¸ŒëŸ¬ë¦¬**
```python
import category_encoders as ce

encoder = ce.OneHotEncoder(cols=categorical_cols, use_cat_names=True)
encoder.fit(X_train)

# ìë™ ì²˜ë¦¬ âœ…
```

---

## ğŸ’¡ **ë‹¹ì‹ ì˜ í”„ë¡œì íŠ¸ì—ì„œëŠ”?**

ì´ë¯¸ `pd.get_dummies()`ë¥¼ ì‚¬ìš© ì¤‘ì´ë¯€ë¡œ:

```python
# âœ… ë°©ë²• 1-A: ìµœì†Œ ìˆ˜ì • (ê¶Œì¥)
# split.pyì—ì„œ feature_columns ì €ì¥
# batch_predict.pyì—ì„œ ì»¬ëŸ¼ ë§ì¶”ê¸°

# ë˜ëŠ”

# âœ… ë°©ë²• 1-B: sklearn OneHotEncoderë¡œ êµì²´
# ì¢€ ë” ê²¬ê³ í•˜ì§€ë§Œ ì½”ë“œ ë§ì´ ë°”ê¿”ì•¼ í•¨
```

---

## ğŸ¯ **ê²°ë¡ **

**ë°©ë²•1 (ì»¬ëŸ¼ ëª©ë¡ ì €ì¥)ì€ ì—…ê³„ í‘œì¤€ì…ë‹ˆë‹¤!**
- scikit-learnë„ ë‚´ë¶€ì ìœ¼ë¡œ ì´ë ‡ê²Œ ë™ì‘
- ì‹¤ë¬´ì—ì„œ ê°€ì¥ ë§ì´ ì‚¬ìš©
- ë‹¹ì‹  ì½”ë“œì— ë”± ë§ìŒ

**ì§€ê¸ˆ ë°”ë¡œ ì ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤!** ğŸš€

ì œê°€ ìˆ˜ì •ëœ ì½”ë“œ ì‘ì„±í•´ë“œë¦´ê¹Œìš”?